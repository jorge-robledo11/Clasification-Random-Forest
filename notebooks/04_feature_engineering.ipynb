{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../src/utils')\n",
    "\n",
    "# Core\n",
    "from utils_functions import *\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "warnings.simplefilter('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11613</th>\n",
       "      <td>52</td>\n",
       "      <td>private</td>\n",
       "      <td>174767</td>\n",
       "      <td>some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>exec-managerial</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>united-states</td>\n",
       "      <td>&gt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48350</th>\n",
       "      <td>29</td>\n",
       "      <td>private</td>\n",
       "      <td>85572</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>never-married</td>\n",
       "      <td>exec-managerial</td>\n",
       "      <td>other-relative</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>united-states</td>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19694</th>\n",
       "      <td>18</td>\n",
       "      <td>private</td>\n",
       "      <td>338632</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>never-married</td>\n",
       "      <td>other-service</td>\n",
       "      <td>own-child</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>united-states</td>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>19</td>\n",
       "      <td>private</td>\n",
       "      <td>375114</td>\n",
       "      <td>hs-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>never-married</td>\n",
       "      <td>craft-repair</td>\n",
       "      <td>not-in-family</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>united-states</td>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>253873</td>\n",
       "      <td>some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not-in-family</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>united-states</td>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt     education  education-num      marital-status  \\\n",
       "11613   52   private  174767  some-college             10  married-civ-spouse   \n",
       "48350   29   private   85572     bachelors             13       never-married   \n",
       "19694   18   private  338632          11th              7       never-married   \n",
       "6106    19   private  375114       hs-grad              9       never-married   \n",
       "2340    27       NaN  253873  some-college             10            divorced   \n",
       "\n",
       "            occupation    relationship   race     sex  capital-gain  \\\n",
       "11613  exec-managerial         husband  white    male             0   \n",
       "48350  exec-managerial  other-relative  white  female             0   \n",
       "19694    other-service       own-child  white    male             0   \n",
       "6106      craft-repair   not-in-family  white  female             0   \n",
       "2340               NaN   not-in-family  white  female             0   \n",
       "\n",
       "       capital-loss  hours-per-week native-country income  \n",
       "11613             0              45  united-states   >50k  \n",
       "48350             0              40  united-states  <=50k  \n",
       "19694             0              16  united-states  <=50k  \n",
       "6106              0              40  united-states  <=50k  \n",
       "2340              0              25  united-states  <=50k  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de los datos\n",
    "data = pd.read_csv('../data/interim/data_preprocessed.csv')\n",
    "data.sample(5, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70% Train set: ((34169, 14), (34169,))\n",
      "20% Validation set: ((9762, 14), (9762,))\n",
      "10% Test set: ((4882, 14), (4882,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separamos los features y el target\n",
    "X = data.loc[:, data.columns != 'income']\n",
    "y = data.loc[:, data.columns == 'income'].squeeze()\n",
    "\n",
    "# Dividir el conjunto original en 70% entrenamiento y 30% para pruebas y validación\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "# Luego, dividir el 30% restante en 20% para validación y 10% para pruebas\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=123, stratify=y_temp)\n",
    "\n",
    "print(f'70% Train set: {X_train.shape, y_train.shape}')\n",
    "print(f'20% Validation set: {X_val.shape, y_val.shape}')\n",
    "print(f'10% Test set: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tTipos de variables\n",
      "Hay 6 variables continuas\n",
      "Hay 0 variables discretas\n",
      "Hay 0 variables temporales\n",
      "Hay 8 variables categóricas\n"
     ]
    }
   ],
   "source": [
    "# Función para capturar los tipos de variables\n",
    "continuous, categoricals, discretes, temporaries = capture_variables(data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables continuas por encima del 5% de datos faltantes:\n",
      "[]\n",
      "\n",
      "Variables continuas por debajo del 5% de datos faltantes:\n",
      "[]\n",
      "\n",
      "Variables categóricas por encima del 5% de datos faltantes:\n",
      "['workclass', 'occupation']\n",
      "\n",
      "Variables categóricas por debajo del 5% de datos faltantes:\n",
      "['native-country']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Variables Continuas ===\n",
    "# Capturemos las variables con alto porcentaje de datos faltantes (más del 5%)\n",
    "continuous_more_than_5perc = [var for var in continuous if X[var].isnull().mean() > 0.05]\n",
    "print(f'Variables continuas por encima del 5% de datos faltantes:\\n{continuous_more_than_5perc}\\n')\n",
    "\n",
    "# Capturemos las variables con menor porcentaje de datos faltantes (menos del 5%)\n",
    "continuous_less_than_5perc = [var for var in continuous if X[var].isnull().sum() > 0 and X[var].isnull().mean() <= 0.05]\n",
    "print(f'Variables continuas por debajo del 5% de datos faltantes:\\n{continuous_less_than_5perc}\\n')\n",
    "\n",
    "# === Variables Categóricas ===\n",
    "# Capturemos las variables con alto porcentaje de datos faltantes (más del 5%)\n",
    "categoricals_more_than_5perc = [var for var in categoricals if X[var].isnull().mean() > 0.05]\n",
    "print(f'Variables categóricas por encima del 5% de datos faltantes:\\n{categoricals_more_than_5perc}\\n')\n",
    "\n",
    "# Capturemos las variables con menor porcentaje de datos faltantes (menos del 5%)\n",
    "categoricals_less_than_5perc = [var for var in categoricals if X[var].isnull().sum() > 0 and X[var].isnull().mean() <= 0.05]\n",
    "print(f'Variables categóricas por debajo del 5% de datos faltantes:\\n{categoricals_less_than_5perc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables categórcias con alta cardinalidad: ['education', 'occupation', 'native-country']\n",
      "Variables categórcias con baja cardinalidad: ['workclass', 'marital-status', 'relationship', 'race', 'sex']\n"
     ]
    }
   ],
   "source": [
    "# Variables categóricas con alta cardinalidad y baja cardinalidad\n",
    "# Por medio del EDA definimos 2 etiquetas en la alta cardinalidad y 5 en la baja cardinalidad de las variables categóricas\n",
    "categoricals_high_cardinality = [var for var in X[categoricals] if X[var].nunique() > 8]\n",
    "categoricals_low_cardinality = [var for var in categoricals if var not in categoricals_high_cardinality]\n",
    "print(f'Variables categórcias con alta cardinalidad: {categoricals_high_cardinality}')\n",
    "print(f'Variables categórcias con baja cardinalidad: {categoricals_low_cardinality}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 76.06309812988381, 0: 23.936901870116188}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificación del target\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.fit_transform(y_val)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# Pesos de las clases\n",
    "unique_values, counts = np.unique(y_train, return_counts=True)\n",
    "percentages = (counts / y_train.shape[0]) * 100\n",
    "class_weight = dict(zip(sorted(unique_values, reverse=True), percentages))\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Selección de variables\n",
    "from feature_engine.selection import DropConstantFeatures\n",
    "from feature_engine.selection import DropDuplicateFeatures\n",
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Ingeniería de variables\n",
    "from feature_engine.imputation import RandomSampleImputer\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    \n",
    "    # === FILTRO BÁSICO ===\n",
    "    # === Cuasi-constantes ===\n",
    "    ('constant', DropConstantFeatures(tol=0.998, missing_values='ignore')),\n",
    "    \n",
    "    # === Duplicados ===\n",
    "    ('duplicated', DropDuplicateFeatures(missing_values='ignore')),\n",
    "    \n",
    "    # === Correlacionados ===\n",
    "    ('correlation', DropCorrelatedFeatures(method='pearson', threshold=0.8, missing_values='ignore')),\n",
    "    \n",
    "    # === IMPUTACIÓN ===\n",
    "    # === Categóricas ===\n",
    "    ('imputer_missing_categoricals_more_than_5perc', RandomSampleImputer(variables=categoricals_more_than_5perc, random_state=42)),\n",
    "    ('imputer_missing_categoricals_less_than_5perc', RandomSampleImputer(variables=categoricals_less_than_5perc, random_state=42)),\n",
    "    \n",
    "    # === ETIQUETAS RARAS ===\n",
    "    # === Categóricas ===\n",
    "    ('rare_label_cat_high_cardinality', RareLabelEncoder(tol=0.05, n_categories=8, \n",
    "                                                         variables=categoricals_high_cardinality)),\n",
    "    ('rare_label_cat_low_cardinality', RareLabelEncoder(tol=0.05, n_categories=8,\n",
    "                                                        variables=categoricals_low_cardinality)),\n",
    "    \n",
    "    # === DISCRETIZACIÓN ===\n",
    "    # === Discretizador ===\n",
    "    ('discretiser', EqualFrequencyDiscretiser(variables=continuous, return_object=True)),\n",
    "    \n",
    "    # === CODIFICACIÓN ===\n",
    "    ('encoder', OrdinalEncoder(encoding_method='ordered', variables=continuous+categoricals)), # Relación monotónica\n",
    "    \n",
    "    # === FEATURES ===\n",
    "    ('features_selector', SelectFromModel(RandomForestClassifier(n_estimators=20, random_state=89, \n",
    "                                                                 class_weight=class_weight)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tResultados de las transformaciones\n",
      "• Features constantes y cuasi-constantes: []\n",
      "• Features duplicados: set()\n",
      "• Features correlacionados: set()\n",
      "• Features no seleccionados: ['age', 'education-num', 'occupation', 'relationship', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "# 1. Ajustemos el Pipeline con los datos de entrenamiento\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 2. Hacemos una transformación: trasladando los cambios del train a los otros conjuntos de datos\n",
    "X_train = pd.DataFrame(pipe.transform(X_train), columns=pipe.get_feature_names_out(), index=X_train.index)\n",
    "X_val = pd.DataFrame(pipe.transform(X_val), columns=pipe.get_feature_names_out(), index=X_val.index)\n",
    "X_test = pd.DataFrame(pipe.transform(X_test), columns=pipe.get_feature_names_out(), index=X_test.index)\n",
    "\n",
    "# Resultados de las transformaciones en la Pipeline\n",
    "print(f\"\"\"\\tResultados de las transformaciones\n",
    "• Features constantes y cuasi-constantes: {pipe.named_steps['constant'].features_to_drop_}\n",
    "• Features duplicados: {pipe.named_steps['duplicated'].features_to_drop_}\n",
    "• Features correlacionados: {pipe.named_steps['correlation'].features_to_drop_}\n",
    "• Features no seleccionados: {[feature for feature, selected in zip(X_train.columns, pipe.named_steps['features_selector'].get_support()) if selected]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el objeto Pipeline en un archivo\n",
    "import joblib\n",
    "\n",
    "del X_train['fnlwgt']\n",
    "del X_val['fnlwgt']\n",
    "del X_test['fnlwgt']\n",
    "\n",
    "joblib.dump(pipe, '../models/pipe.pkl')\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_val.to_csv('../data/processed/X_val.csv', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "\n",
    "pd.Series(y_train).to_csv('../data/processed/y_train.csv', index=False)\n",
    "pd.Series(y_val).to_csv('../data/processed/y_val.csv', index=False)\n",
    "pd.Series(y_test).to_csv('../data/processed/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
